{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 10:25:05.120515: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-11 10:25:05.463213: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-11 10:25:05.465911: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-11 10:25:09.188984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE # automatyczne dostosowanie liczby wątków i buforów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training example for one sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence = \"The wide road shimmered in the hot sun\"\n",
    "sentence = \"Mary has a little lamb\"\n",
    "tokens = sentence.lower().split()\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'mary': 1, 'has': 2, 'a': 3, 'little': 4, 'lamb': 5}\n",
      "{0: '<pad>', 1: 'mary', 2: 'has', 3: 'a', 4: 'little', 5: 'lamb'}\n"
     ]
    }
   ],
   "source": [
    "# create vocabulary and inverse vocabulary\n",
    "vocab, inverse_vocab, i = {}, {}, 0\n",
    "\n",
    "for token in [\"<pad>\"] + tokens:\n",
    "    if token not in vocab:\n",
    "        vocab[token] = i\n",
    "        inverse_vocab[i] = token\n",
    "        i += 1\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(vocab, inverse_vocab, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize sentences\n",
    "example_sequence = [vocab[word] for word in tokens]\n",
    "example_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "(3, 1): (a, mary)\n",
      "(3, 5): (a, lamb)\n",
      "(4, 3): (little, a)\n",
      "(5, 4): (lamb, little)\n",
      "(3, 4): (a, little)\n"
     ]
    }
   ],
   "source": [
    "# generate skip-grams\n",
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0)\n",
    "\n",
    "print(len(positive_skip_grams))\n",
    "\n",
    "for target, context in positive_skip_grams[:5]:\n",
    "  print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a mary\n",
      "tf.Tensor([2 1 3 0], shape=(4,), dtype=int64)\n",
      "['has', 'mary', 'a', '<pad>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 10:25:17.361953: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# generate neagtive samples – context word other than assigned in positive skip-gram\n",
    "\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "num_ns = 4 # number of negative samples per positive context\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class, # class that should be sampled as 'positive'\n",
    "    num_true=1, # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns,\n",
    "    unique=True, # the negative samples should be unique\n",
    "    range_max=vocab_size, # pick index of the samples from [0, vocab_size]\n",
    "    seed = SEED,\n",
    "    name=\"negative_sampling\" # name of this operation\n",
    ")\n",
    "\n",
    "print(inverse_vocab[target_word], inverse_vocab[context_word])\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_context_class = tf.squeeze(context_class, 1) # from [[5]] to [5]\n",
    "context = tf.concat([squeezed_context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\") # first is positive, rest is negative\n",
    "target = target_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target          : 3\n",
      "target_word     : a\n",
      "context         : [1 2 1 3 0]\n",
      "context_words   : ['mary', 'has', 'mary', 'a', '<pad>']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"target          : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context         : {context}\")\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(\n",
    "    size=10) # prob of sampling i-th common word in dataset (assuming Zipf's distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(sequences: list, window_size: int, num_ns: int, vocab_size: int, seed: int) -> list:\n",
    "    # @param sequence: list of lists of tokens\n",
    "    # @param window_size: context window size\n",
    "    # @param num_ns: number of negative samples per positive context word\n",
    "    # @param vocab_size: size of the vocabulary\n",
    "    # @param seed: seed for random number generator\n",
    "\n",
    "    targets, contexts, labels = [], [], []\n",
    "\n",
    "    # prob of sampling i-th common word in dataset (assuming Zipf's distribution)\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=vocab_size)\n",
    "\n",
    "    for sequence in tqdm.tqdm(sequences): # tqdm creates progress bar\n",
    "        # generate positive skip-grams\n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "        sequence,\n",
    "        sampling_table=sampling_table,\n",
    "        vocabulary_size=vocab_size,\n",
    "        window_size=window_size,\n",
    "        negative_samples=0)\n",
    "\n",
    "        # generate neagtive samples – context word other than assigned in positive skip-gram\n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                true_classes=context_class, # class that should be sampled as 'positive'\n",
    "                num_true=1, # each positive skip-gram has 1 positive context class\n",
    "                num_sampled=num_ns,\n",
    "                unique=True, # the negative samples should be unique\n",
    "                range_max=vocab_size, # pick index of the samples from [0, vocab_size]\n",
    "                seed = SEED,\n",
    "                name=\"negative_sampling\" # name of this operation\n",
    "            )   \n",
    "\n",
    "            targets.append(target_word)\n",
    "            contexts.append(tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0))\n",
    "            labels.append(tf.constant([1] + [0]*num_ns, dtype=\"int64\"))  # first is positive, rest is negative        \n",
    "        \n",
    "    return targets, contexts, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=bool, numpy=array([[ True]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.constant(5, dtype=\"int64\"), (1, 1)) == tf.expand_dims(\n",
    "    tf.constant([5], dtype=\"int64\"), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as f:\n",
    "    for i in range(10):\n",
    "        print(f.readline(), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty lines\n",
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(\n",
    "    lambda x: tf.cast(tf.strings.length(x), bool)) # True if len > 0 False otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "  ### lowercase and remove punctuation\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  return tf.strings.regex_replace(lowercase,'[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "vocab_size = 4096\n",
    "sequence_length = 10\n",
    "\n",
    "# normalize, split, and map strings to integers\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length # pad or truncate to the same length\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 10:25:17.654698: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'and', 'to']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "vectorize_layer.adapt(text_ds.batch(1024))\n",
    "\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "inverse_vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data in text_ds using the built vocabulary\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 10:25:26.259686: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype resource\n",
      "\t [[{{node Placeholder/_9}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32777\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
      "[138  36 982 144 673 125  16 106   0   0] => ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n",
      "[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n",
      "[106 106   0   0   0   0   0   0   0   0] => ['speak', 'speak', '', '', '', '', '', '', '', '']\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
      "[   7   41   34 1286  344    4  200   64    4 3690] => ['you', 'are', 'all', 'resolved', 'rather', 'to', 'die', 'than', 'to', 'famish']\n",
      "[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n",
      "[1286 1286    0    0    0    0    0    0    0    0] => ['resolved', 'resolved', '', '', '', '', '', '', '', '']\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
      "[  89    7   93 1187  225   12 2442  592    4    2] => ['first', 'you', 'know', 'caius', 'marcius', 'is', 'chief', 'enemy', 'to', 'the']\n"
     ]
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))\n",
    "for seq in sequences[:10]:\n",
    "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the lines were changed to lowercase, splitted, the stopwords were removed. The lines were truncated or padded with '' to match the length 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32777/32777 [01:46<00:00, 307.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "targets.shape: (65601,)\n",
      "contexts.shape: (65601, 5)\n",
      "labels.shape: (65601, 5)\n"
     ]
    }
   ],
   "source": [
    "# generate traing data\n",
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=2,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=SEED)\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article about Embedding layer: https://medium.com/analytics-vidhya/understanding-embedding-layer-in-keras-bbe3ff1327ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = layers.Embedding(vocab_size, #input_size\n",
    "                                      embedding_dim,     # output size\n",
    "                                      input_length=1,    # pass one word at once\n",
    "                                      name=\"w2v_embedding\")\n",
    "    self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                       embedding_dim,\n",
    "                                       input_length=num_ns+1) # pass all context words at once \n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    # target is (batch_size, 1), context is (batch_size, num_ns+1)\n",
    "    if len(target.shape) == 2:\n",
    "      target = tf.squeeze(target, axis=1)\n",
    "    # target: (batch_size,)\n",
    "    word_emb = self.target_embedding(target)\n",
    "    # word_emb: (batch_size, embed)\n",
    "    context_emb = self.context_embedding(context)\n",
    "    # context_emb: (batch_size, num_ns+1, embed)\n",
    "    dots = tf.einsum('be,bce->bc', word_emb, context_emb) # dimensions of wordemb is batch_szie (b) and embed (e). For context is batch_size (b), num_ns+1 (c) and embed (e). Result is batch_size (b) and num_ns+1 (c).\n",
    "    # So we perform the dot product over embedding (e) dimension.\n",
    "    # dots: (batch_size, context)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is trying to learn the context based on the target word. It generates the embeddings for both and then measures the simmilarity between them. We use two separate layers, because of other functions for embeddings. One of it learns word as it is and one of it learns the word as a context. It was proven to work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensorboard statistics\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 10:27:38.424208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [65601,5]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-10-11 10:27:38.424593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int64 and shape [65601,5]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 6s 27ms/step - loss: 1.6083 - accuracy: 0.2350\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 1.5887 - accuracy: 0.5507\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 1.5398 - accuracy: 0.5858\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 1.4561 - accuracy: 0.5569\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 1.3588 - accuracy: 0.5704\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 1.2632 - accuracy: 0.6012\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 1.1740 - accuracy: 0.6360\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 1.0909 - accuracy: 0.6719\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 1.0138 - accuracy: 0.7056\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.9420 - accuracy: 0.7350\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 3s 50ms/step - loss: 0.8753 - accuracy: 0.7607\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 2s 32ms/step - loss: 0.8137 - accuracy: 0.7827\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7569 - accuracy: 0.8024\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7047 - accuracy: 0.8197\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6569 - accuracy: 0.8346\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6133 - accuracy: 0.8479\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.5734 - accuracy: 0.8604\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.5371 - accuracy: 0.8712\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.5040 - accuracy: 0.8815\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4739 - accuracy: 0.8903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec940c6170>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-98fd33fba11e0b51\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-98fd33fba11e0b51\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_wectors = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/dane/projekty/moje/ml/natural_language_processing/Word2vec.ipynb Komórka 36\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/dane/projekty/moje/ml/natural_language_processing/Word2vec.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# skip 0, it's padding.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/dane/projekty/moje/ml/natural_language_processing/Word2vec.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   vec \u001b[39m=\u001b[39m words_wectors[index]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/dane/projekty/moje/ml/natural_language_processing/Word2vec.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   out_v\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m vec]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/dane/projekty/moje/ml/natural_language_processing/Word2vec.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   out_m\u001b[39m.\u001b[39mwrite(word \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/dane/projekty/moje/ml/natural_language_processing/Word2vec.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m out_v\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_v' is not defined"
     ]
    }
   ],
   "source": [
    "imageout_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = words_wectors[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://projector.tensorflow.org/?_gl=1*1ec0dl2*_ga*NDE0Mzk1NjcyLjE2OTY2NjYyODU.*_ga_W0YLR4190T*MTY5Njk0NDQ2Ni43LjEuMTY5Njk0NzUxNy4wLjAuMA..\n",
    "\n",
    "![Visualisation](embeddings2D.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def evaluate_tf_model(word2vec, embedding_dim):\n",
    "    words_wectors = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "\n",
    "    # Convert tf model to gensim one\n",
    "    gensim_model = KeyedVectors(vector_size=embedding_dim)\n",
    "    gensim_model.add_vectors(vocab, words_wectors)\n",
    "\n",
    "    # Evaluate word similarity\n",
    "    similarity_score = gensim_model.similarity('brother', 'sister')\n",
    "    print(\"sim brother, sister\", similarity_score)\n",
    "\n",
    "    similarity_score = gensim_model.similarity('brother', 'make')\n",
    "    print(\"sim brother, make\", similarity_score)\n",
    "\n",
    "    # Find similar words\n",
    "    similar_words = gensim_model.most_similar('brother')\n",
    "    print(\"most similar to brother: \", similar_words)\n",
    "\n",
    "    # Evaluate word analogy\n",
    "    analogy_result = gensim_model.most_similar(positive=['king', 'woman'], negative=['man'])\n",
    "    print(\"king - man + woman = \", analogy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('iv', 0.34329548478126526), ('triumphant', 0.34055984020233154), ('ye', 0.33662500977516174), ('conveyd', 0.33429524302482605), ('richard', 0.32999661564826965), ('ii', 0.30728983879089355), ('henry', 0.3062649667263031), ('iii', 0.3016456663608551), ('lovers', 0.3012474477291107), ('vi', 0.30031704902648926)]\n"
     ]
    }
   ],
   "source": [
    "evaluate_tf_model(word2vec, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results doesn't seem good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 2s 30ms/step - loss: 1.6070 - accuracy: 0.2419\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 1.5695 - accuracy: 0.6316\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 1.4892 - accuracy: 0.6472\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.3700 - accuracy: 0.6272\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.2410 - accuracy: 0.6516\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 1.1179 - accuracy: 0.6936\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 30ms/step - loss: 1.0035 - accuracy: 0.7352\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.8995 - accuracy: 0.7721\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.8055 - accuracy: 0.8018\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.7213 - accuracy: 0.8267\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 2s 30ms/step - loss: 0.6476 - accuracy: 0.8485\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.5832 - accuracy: 0.8674\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.5269 - accuracy: 0.8827\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.4789 - accuracy: 0.8964\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.4368 - accuracy: 0.9079\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.4002 - accuracy: 0.9176\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.3689 - accuracy: 0.9242\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.3415 - accuracy: 0.9311\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.3177 - accuracy: 0.9363\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.2966 - accuracy: 0.9405\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.2781 - accuracy: 0.9439\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.2622 - accuracy: 0.9468\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.2475 - accuracy: 0.9495\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.2347 - accuracy: 0.9512\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.2237 - accuracy: 0.9529\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.2134 - accuracy: 0.9540\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.2044 - accuracy: 0.9551\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1959 - accuracy: 0.9566\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 0.1884 - accuracy: 0.9574\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.1818 - accuracy: 0.9580\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.1757 - accuracy: 0.9585\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1701 - accuracy: 0.9594\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.1650 - accuracy: 0.9599\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.1600 - accuracy: 0.9604\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 0.1561 - accuracy: 0.9608\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 0.1521 - accuracy: 0.9614\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1484 - accuracy: 0.9616\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1451 - accuracy: 0.9618\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.1420 - accuracy: 0.9626\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.1390 - accuracy: 0.9628\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.1363 - accuracy: 0.9625\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1338 - accuracy: 0.9625\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1317 - accuracy: 0.9626\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1296 - accuracy: 0.9626\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1273 - accuracy: 0.9628\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.1254 - accuracy: 0.9628\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.1237 - accuracy: 0.9628\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.1221 - accuracy: 0.9634\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.1204 - accuracy: 0.9631\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1190 - accuracy: 0.9631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd829e33dc0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim_2 = 256\n",
    "word2vec_2 = Word2Vec(vocab_size, embedding_dim_2)\n",
    "word2vec_2.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "word2vec_2.fit(dataset, epochs=35, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim brother, sister 0.038001135\n",
      "sim brother, make -0.07777563\n",
      "most similar to brother:  [('familiar', 0.3976895213127136), ('waked', 0.3845680058002472), ('stood', 0.3626787066459656), ('subtle', 0.3443647027015686), ('wounded', 0.3273954689502716), ('sceptres', 0.30579644441604614), ('choleric', 0.29051488637924194), ('impossible', 0.2879590094089508), ('wrongfully', 0.2862926423549652), ('himself', 0.28537046909332275)]\n",
      "king - man + woman =  [('richard', 0.2890335023403168), ('conveyd', 0.2626268267631531), ('3', 0.2621176540851593), ('ii', 0.25475478172302246), ('purse', 0.2537199854850769), ('fourteen', 0.25072288513183594), ('vi', 0.24345341324806213), ('troubled', 0.24259331822395325), ('ye', 0.24201162159442902), ('kissing', 0.23922547698020935)]\n"
     ]
    }
   ],
   "source": [
    "evaluate_tf_model(word2vec_2, embedding_dim_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
