{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhIZIpEnr8P6"
      },
      "source": [
        "# BERT\n",
        "\n",
        "At todays meeting, we're going to focus on BERT -- a model, which transforms our tokens into contextual word embeddings, that are of great quality!\n",
        "\n",
        "We will use `transformers` library for that purpose, so let's install it first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKMUJ2X5AXQe",
        "outputId": "491ef2a1-625b-4fcc-c7aa-4b2f95f02149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (4.20.1)\n",
            "Requirement already satisfied: filelock in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from transformers) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/anna/.local/lib/python3.10/site-packages (from transformers) (1.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/anna/.local/lib/python3.10/site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/anna/.local/lib/python3.10/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (2023.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/anna/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/anna/.conda/envs/ml/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr8B0bjk-Y-J"
      },
      "source": [
        "#BERT\n",
        "\n",
        "## Task 1: Tokenization using WordPiece\n",
        "\n",
        "Below you can find a simple fragment of code, which downloads a `bert-base` model (an `uncased` version -- this model introduced a preprocessing step on the data that transformed each text into lowercased text) and instantiates appropriate tokenizer for that model. You can learn about this particular model here: https://huggingface.co/bert-base-uncased (I encourage you to read the description! Many models hosted on the huggingface website have great documentations and it's always worth checking them).\n",
        "\n",
        "Then, in line 4, we define a text to be tokenized, run the tokenizer in line 5, and use the tokenized input as the input to BERT model, which is called in line 6.\n",
        "\n",
        "Please, run the code below. We generated BERT embeddings using 6 lines of code! ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U5MBbap-cOL",
        "colab": {
          "referenced_widgets": [
            "3d482927c6e643b7aa977e4a2e3ae7d9",
            "de78414badca4f12ae998148566cc2d0",
            "c74fed0b93fd44cc8a7d1b173b988d04",
            "446b9f6cd4464d3eb5cd0785b1a35916"
          ]
        },
        "outputId": "f822a4f1-534d-4f48-8995-be73953c86c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d482927c6e643b7aa977e4a2e3ae7d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de78414badca4f12ae998148566cc2d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c74fed0b93fd44cc8a7d1b173b988d04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "446b9f6cd4464d3eb5cd0785b1a35916",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6lcMqMBJBAj"
      },
      "source": [
        "Runnning tokenizer by simply calling the tokenizer object (`tokenizer(text, return_tensors='pt')`) returns a dictionary containing 3 keys: `input_ids`, `token_type_ids`, and `attention_mask`. As for now, let's focus on `input_ids` only.\n",
        "\n",
        "You may visit the website: https://huggingface.co/docs/transformers/glossary to learn more about the role of `token_type_ids` and `attention_mask`.\n",
        "\n",
        "\n",
        "The `input_ids` is a list of lists (represented as a tensor). The outer list collects documents, while the inner lists collect tokens in that document. Here, we processed only one document (sentence) so that there is only one \"outer\" list.\n",
        "\n",
        "Each of the inner lists contains a seqeunce of identifiers. These are the positions of tokens in the Vocabulary. They can be used to generate one-hot encoding representations for our words, since if we know the length of a vocabulary and know the position of a given token in the vocabulary, we can generate a vector of the vocabulary length that is filled with zeros, then we set the value assigned to a token position to 1 to generate one-hot encoding.\n",
        "\n",
        "To produce the ids, we have to tokenize our text first.\n",
        "\n",
        "Moreover, those identifiers require less memory that storing tokens as strings!\n",
        "\n",
        "Run the code below, to see the tokenizer's output. Please note that the number of token identifiers generated by the tokenizer is not equal to the number of tokens in the sequence. We'll see why is that in a minute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm01ajH4_-H-",
        "outputId": "86c6a40f-4a84-40e3-b7d6-3b32922bb952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJBdCDgkCzy1",
        "outputId": "58b7f8fb-21a4-477f-f418-c630ad2781d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7 12\n"
          ]
        }
      ],
      "source": [
        "print(len(text.split()), len(encoded_input['input_ids'][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZoJWPXcqJzf"
      },
      "source": [
        "The ids generated by the tokenizer are not human readable. However, the tokenizer contains a mapping which relates known tokens to their positions, so that we can use it to map ids to tokens back!\n",
        "\n",
        "The first line of code obtains the input ids defined for the first sequence provided.\n",
        "Then, we call `convert_ids_to_tokens` to transform those ids to tokens. Please run the code and analyze the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYIdWHlxAnIj",
        "outputId": "96d548ac-a917-4a33-a634-cb7dee36e8f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'replace',\n",
              " 'me',\n",
              " 'by',\n",
              " 'any',\n",
              " 'text',\n",
              " 'you',\n",
              " \"'\",\n",
              " 'd',\n",
              " 'like',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_sentence_ids = encoded_input['input_ids'][0]\n",
        "tokenizer.convert_ids_to_tokens(first_sentence_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKQJ9jH2qp07"
      },
      "source": [
        "Whoa, we see that the tokenizer not only tokenizes our text (splits into tokens), but it also generated special tokens required by our model! Nice. Please note that after tokenization we don't have capital letters in our tokens. This is caused by the use of the `bert-base-uncased` model. Since the model was trained on lowercased data, the tokenizer also ensures that the tokens are lowercased.\n",
        "\n",
        "\n",
        "## Subword units\n",
        "\n",
        "However, the length of the generated `input_ids` may be even bigger as related to the length of our text. Sometimes, the vocabulary doesn't contain a given word as a whole. Since BERT used WordPiece tokenization, to handle such cases, the tokenizer tries to split those words into smaller fragments, that are stored in our vocabulary. Let's tokenize some document containing rare words and see the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZTIXMpDAqwo",
        "outputId": "988f87aa-6e0d-4874-8ace-578433ffc1d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[101, 1050, 17258, 2401, 1040, 2290, 2595, 17350, 8889, 102]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer_output = tokenizer(['NVIDIA DGX A100'])\n",
        "\n",
        "input_ids = tokenizer_output['input_ids'][0]\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VozPQjo7ruWC"
      },
      "source": [
        "Whoa, we see that as a result of tokenization, we obtained many tokens. Let's see what they represent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhvna3O5Asl0",
        "outputId": "96e0a16c-a200-4b40-eb5a-3f3ab0e71d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]', 'n', '##vid', '##ia', 'd', '##g', '##x', 'a1', '##00', '[SEP]']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e9XJATrtKaW"
      },
      "source": [
        "Ah, as we can see, the vocabulary assigned to `bert-base` doesn't contain tokens such as \"nvidia\", \"dgx\" and \"a100\", that's why they are split into subwrod units.\n",
        "\n",
        "Each time a given subword unit starts with a double hash (##), we know that this subword unit is a continuation of the previous token.\n",
        "\n",
        "We can use this information to reconstruct the original text, by joining those subword units (sometimes called subtokens) into full tokens. We can achieve this goal using the following line of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SfeJFf4BU8H",
        "outputId": "845a3de2-dfd1-41dd-c54a-9090975fb0bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-02 10:39:41.951895: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-02 10:39:42.237543: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-02 10:39:43.357245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'[CLS] nvidia dgx a100 [SEP]'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78qbqsgItqoi"
      },
      "source": [
        "If we know how to map tokens to their positions in the vocabulary, the only missing part is to determine how long our one-hot-encoding vector should be (or how big is our vocabulary).\n",
        "\n",
        "This transformation of ids into one-hot-encodings is done automatically by the `transformer` library. However, you can check the size of the vocabulary easily using the following line of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD4qXpxNB9fG",
        "outputId": "6b793eb0-490f-43d5-b3cf-d90cc8a3d004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTw0zxjwuctL"
      },
      "source": [
        "## Task 2: Using a pre-trained BERT to generate features that may be used to solve a classification task.\n",
        "\n",
        "As we discussed during the lecture, we can generate a fixed-length vector represening any input by taking the embedding produced for the `[CLS]` token (which is a representation of the whole seqeunce).\n",
        "\n",
        "In this task, your goal is to use a pre-trained BERT model to obtain representations for a given dataset. Then, these representations will be used to train a logistic regression model.\n",
        "\n",
        "We will try to genearate a solution that can detect whether a given review is positive or not!\n",
        "\n",
        "For that purpose we're going to use a BERT variant called `distilBERT`. We didn't cover it during the lecture, because it is related to the concept of distillation that will be very important to us and I'll make a separate lecture on it.\n",
        "\n",
        "For now, we can treat `distilBERT` the same way as BERT. In fact, this is a compressed BERT model. It behaves the same way but it is distilled so that we aimed to achieve similar quality using less parameters.\n",
        "\n",
        "Please follow the tutorial you can find here: https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb (there is even a blogpost related to this tutorial: http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)\n",
        "\n",
        "\n",
        "Just copy and paste fragments of code here and observe the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlRMuDYsw65f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mF4hRXbCzy8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqKeoEs-Czy9",
        "outputId": "489a97fe-bd33-499a-def0-2347ff4ecf7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    1041\n",
              "0     959\n",
              "Name: 1, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_1 = df[:2000] # cut dataset for performance reasons\n",
        "batch_1[1].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c81c94e91e16437f991a5498614e0ac8",
            "fe97ed2fdd1b48adbfb32391135c374f",
            "3938bb1fce7c4f51aa99dc1bd956c9af",
            "b634d04dcc47471f84333611cd2680b9"
          ]
        },
        "id": "0-crO3ijCzy9",
        "outputId": "3445fb16-5a17-46ee-d1ba-09d47778268d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c81c94e91e16437f991a5498614e0ac8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe97ed2fdd1b48adbfb32391135c374f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3938bb1fce7c4f51aa99dc1bd956c9af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b634d04dcc47471f84333611cd2680b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# load pretrained distilbert\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy3jQZn-Czy9",
        "outputId": "c0cc106b-ef2f-4bbb-d9e5-4ec425aa7ea0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(transformers.models.distilbert.modeling_distilbert.DistilBertModel,\n",
              " transformers.models.distilbert.tokenization_distilbert.DistilBertTokenizer)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_class, tokenizer_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twMme8xZCzy-",
        "outputId": "0e81580f-259c-4188-8704-908937f3e2ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 59)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "# pad to the same size so we can use them as batch\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\n",
        "np.array(padded).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFzZ3tD_Czy-",
        "outputId": "4ff7c130-6b39-45ab-ac39-7f3055cafd8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 59)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# say bert that we have padded tokens\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTJMKfHICzy_"
      },
      "outputs": [],
      "source": [
        "input_ids = torch.tensor(padded)\n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl4v7IPyCzy_"
      },
      "outputs": [],
      "source": [
        "# get embedding for [CLS] token, representing the whole sentence\n",
        "features = last_hidden_states[0][:,0,:].numpy()\n",
        "labels = batch_1[1] # positive or negative sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGrXjpFJCzy_"
      },
      "outputs": [],
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLJg3AZlCzy_",
        "outputId": "18b444b5-6f61-4b3a-ac6d-22b0fe20fad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 5.263252631578947}\n",
            "best scrores:  0.8033333333333333\n"
          ]
        }
      ],
      "source": [
        "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        "grid_search.fit(train_features, train_labels)\n",
        "\n",
        "print('best parameters: ', grid_search.best_params_)\n",
        "print('best scrores: ', grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGTZN6U7Czy_",
        "outputId": "f0759262-987f-406a-aa85-66d0d7b294df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=5.263157894736842)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=5.263157894736842)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=5.263157894736842)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train logistic regression on top of bert embeddings\n",
        "\n",
        "lr_clf = LogisticRegression(C=5.263157894736842)\n",
        "lr_clf.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW91-Kv2CzzA",
        "outputId": "f2744185-5c12-4d5b-a0c7-3127c220dbd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.836"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J6BqCvOCzzA",
        "outputId": "ecbad4c0-ca85-43a8-9413-80b960dd8a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.521 (+/- 0.00)\n"
          ]
        }
      ],
      "source": [
        "# get dummy classifier score as a baseline\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFGIZAN6xEsT"
      },
      "source": [
        "## Task 3(Optional - not required): fine-tuning BERT\n",
        "\n",
        "In the example above, a BERT model (or more precisely it's smaller family member: distilBERT) was used only to deliver vectors representing whole documents.\n",
        "\n",
        "Now we would like to fine-tune an existing model. As we discussed during the lecture, we can achieve it by simply switching the top-layer of the network. Instead of solving the Masked Language Model and Next Sentence Prediction tasks, we may add our own classification layer (also referred to as a classification head) and train our whole network to solve a given task.\n",
        "\n",
        "There is a great and easy to follow tutorial on fine-tuning, available here: https://github.com/huggingface/notebooks/blob/main/transformers_doc/training.ipynb\n",
        "\n",
        "If you want, please follow that tutorial (you can copy-and-paste the code snippets from the notebook here)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI8IwQgHCzzB"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"yelp_review_full\")\n",
        "dataset[\"train\"][100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmw97AKcCzzB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "from datasets import load_from_disk\n",
        "\n",
        "try:\n",
        "    !tar -xzvf ./tokenized_dataset.tar.gz\n",
        "    tokenized_dataset = load_from_disk('./tokenized_dataset')\n",
        "except:\n",
        "    tokenized_dataset = dataset.map(lambda x: tokenizer(x['text'], truncation=True, padding=\"max_length\"), batched=True)\n",
        "    tokenized_dataset.save_to_disk('./tokenized_dataset')\n",
        "    !tar -czvf ./tokenized_dataset.tar.gz ./tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AcQVNwsICzzB"
      },
      "outputs": [],
      "source": [
        "# get smaller dataset for performance reasons\n",
        "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aLGld4ASCzzB",
        "outputId": "d3a1a3d1-65da-402a-d11c-e16673a495f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "### easy â€“ Trainer class from transformers\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5) # 5 is num of classes in this dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xpwp7tG5CzzC"
      },
      "outputs": [],
      "source": [
        "# hyperparameters and training options\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\") # dir to save checkpoints and monitoring results each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aGB1-zBZCzzC",
        "outputId": "6b5b3165-2ac6-4def-faa8-0f6bcf647f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "1611287c8bcf4f578e0d4893f0bbcee6",
            "d5cb08cc0d414bd5bebe681b82de13c9",
            "9337e8d610844cf8bdf0377a284db4d9",
            "4314d1e5d4514b77b3dda77174cc68b4",
            "17db5db4af0c4f6488cd88ff5bd103c0",
            "f6f3b4045c1b411ab019218d2ff5c44b",
            "123b3d8e24e64627825be5bbf85246b4",
            "eeaa55a19a6e4024895bdbf1dec5608d",
            "b1907319558642008eaec7d535cacb1d",
            "1fce37305fb54fcf9355736cc3993212",
            "31506f62dc7a4937a83abc4f5df8e31f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-66a42e67f145>:6: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"accuracy\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1611287c8bcf4f578e0d4893f0bbcee6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# track accuracy during training\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ib3owvEQCzzD",
        "outputId": "80de6455-a8db-4369-8a6b-944368cb894a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 06:48, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.100781</td>\n",
              "      <td>0.572000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.131317</td>\n",
              "      <td>0.574000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.216907</td>\n",
              "      <td>0.586000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=375, training_loss=0.6678494059244792, metrics={'train_runtime': 408.8367, 'train_samples_per_second': 7.338, 'train_steps_per_second': 0.917, 'total_flos': 789354427392000.0, 'train_loss': 0.6678494059244792, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# train\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_example_dataset = small_eval_dataset.select(range(1))\n",
        "predictions = trainer.predict(one_example_dataset)\n",
        "print(f'{one_example_dataset[0][\"text\"]}\\ntrue_label: {one_example_dataset[0][\"label\"]}\\npredicted label: {predictions[1][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "OhEKuc6D6cAL",
        "outputId": "815132c1-f8dc-4deb-e5a5-87a1791c5183"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kabuto is your run-of-the-mill Japanese Steakhouse. Different stations with chefs slinging shrimp tails around the communal dining areas like it's a lunchtime magic show. Always a plethora of laughs and gags going around the group. \\n\\nThis place is great for lunch. $9 and 30 minutes and you're out the door. Uhhh...If I'm craving a salad with ginger dressing, which I always am, (you do too. admit it) fried rice, steak, shrimp and white sauce (DUDE) then Kabuto is king of lunch options in my book. Always super clean and full of kindhearted staff. The parking lot is super difficult to get in and out of though. 51 traffic at lunch is a beast. Good luck getting stuck behind someone trying to cut across traffic at 12pm on a weekday. It's murder. This place would greatly benefit from another exit/entrance or a stoplight. Here's hoping....\\n\\nYou can't really shake a stick at balanced lunch when you can have soup or a salad, veggies, fried rice and a choice of a protein for under $10 and be back out the door and headed back to the office or meeting. Glad to see these guys have taken this into account. Though, you should know that the $10 offering mostly comes in the protein department. Some may require more steak or chicken, which can be sparse. \\n\\nService is always quick and friendly. They do a wonderful job of memorizing orders. Rarely has it come to pass that my order has been mal-delivered. Quick on refills and I love that they always offer a to-go beverage. \\\"Why, yes! I would love a diet coke to go! How thoughtful!\\\" Pretty much always my thought process. \\n\\nThis place also does full dinner options and has sushi. Neither of which I have tried to date, but would happily oblige if the option was presented. \\n\\nThanks for the quick and entertaining lunch/service, Kabuto!\n",
            "true_label: 2\n",
            "predicted label: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MM_rGXeCzzD",
        "outputId": "eeae029f-09bb-4530-c104-7ed5c7275c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'])\n"
          ]
        }
      ],
      "source": [
        "print(small_train_dataset[100].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH9mfen4CzzD"
      },
      "outputs": [],
      "source": [
        "### KERAS\n",
        "from transformers import DefaultDataCollator\n",
        "\n",
        "# collator converts data to tf tensors and batch them\n",
        "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
        "\n",
        "# convert do tf dataset\n",
        "tf_train_dataset = small_train_dataset.to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
        "    label_cols=[\"labels\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=8,\n",
        ")\n",
        "\n",
        "tf_validation_dataset = small_eval_dataset.to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
        "    label_cols=[\"labels\"],\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "9b86d63e44e745a0b1df757186295164"
          ]
        },
        "id": "hFTQmVs8CzzE",
        "outputId": "10c6f1c3-12e3-4e76-b3c9-ea737b845ab9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b86d63e44e745a0b1df757186295164",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "125/125 [==============================] - 215s 1s/step - loss: 1.5734 - sparse_categorical_accuracy: 0.2570 - val_loss: 1.3903 - val_sparse_categorical_accuracy: 0.3360\n",
            "Epoch 2/3\n",
            "125/125 [==============================] - 201s 2s/step - loss: 1.2290 - sparse_categorical_accuracy: 0.4580 - val_loss: 1.2083 - val_sparse_categorical_accuracy: 0.4880\n",
            "Epoch 3/3\n",
            "125/125 [==============================] - 162s 1s/step - loss: 0.9791 - sparse_categorical_accuracy: 0.5680 - val_loss: 1.0403 - val_sparse_categorical_accuracy: 0.5460\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bd25b58be50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "# create a model from pretrained bert and train it\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
        ")\n",
        "\n",
        "model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# free some memory\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "q6yESUoI9kqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "1YNGLtnKCzzE"
      },
      "outputs": [],
      "source": [
        "### PYTORCH\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# prepare dataset\n",
        "tokenized_datasets_torch = tokenized_dataset.remove_columns([\"text\"]) # model doesn't accept raw text\n",
        "tokenized_datasets_torch = tokenized_datasets_torch.rename_column(\"label\", \"labels\") # model expects \"labels\"\n",
        "tokenized_datasets_torch.set_format(\"torch\") # convert to pytorch tensors\n",
        "\n",
        "# get smaller piece\n",
        "small_train_dataset = tokenized_datasets_torch[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_datasets_torch[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "# to iterate over batches\n",
        "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
        "eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "OmG9OjfyCzzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc2ee23-3523-4d86-d8e7-9697b60ce55c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification # not tf this time\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# move model to GPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "metric.compute()"
      ],
      "metadata": {
        "id": "JLC7UNHME5mr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "39c15a4ad85541718068afe18c3d9aa6",
            "cbcb5ad7277a4e928359b5f177aeef3c",
            "0563d1194dda460384d0fef128cc9578",
            "e059e3ab58f34eca9803f94c84aa9a53",
            "ee52f0aeb04d44698964ee02f072de36",
            "65922efd98d24ae6a0ee9d669ec7bfdd",
            "a4fe6592830b444f894b15681e501ef3",
            "0561fcbcb81d4c84837cb1f4a2127f9c",
            "ce8a668445c440c4bf30427b74981665",
            "983e4cd11dd34adbb346858056e646de",
            "1cce1243aebe43e39cef37744d51a1a6"
          ]
        },
        "outputId": "deb75459-e34a-4a5e-8b6d-dcc82e6e177f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/375 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39c15a4ad85541718068afe18c3d9aa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.571}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "    break\n",
        "logits = outputs.logits\n",
        "predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "example = small_eval_dataset.select(range(1))[0]\n",
        "print(f'{tokenizer.decode(example[\"input_ids\"])}\\ntrue label: {example[\"labels\"]}\\npredicted label: {predictions[0]}')\n"
      ],
      "metadata": {
        "id": "-WRol8JVKuwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0922b7f8-2a63-48b1-9c13-6a9321e3f3dd"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] Kabuto is your run - of - the - mill Japanese Steakhouse. Different stations with chefs slinging shrimp tails around the communal dining areas like it's a lunchtime magic show. Always a plethora of laughs and gags going around the group. \\ n \\ nThis place is great for lunch. $ 9 and 30 minutes and you're out the door. Uhhh... If I'm craving a salad with ginger dressing, which I always am, ( you do too. admit it ) fried rice, steak, shrimp and white sauce ( DUDE ) then Kabuto is king of lunch options in my book. Always super clean and full of kindhearted staff. The parking lot is super difficult to get in and out of though. 51 traffic at lunch is a beast. Good luck getting stuck behind someone trying to cut across traffic at 12pm on a weekday. It's murder. This place would greatly benefit from another exit / entrance or a stoplight. Here's hoping.... \\ n \\ nYou can't really shake a stick at balanced lunch when you can have soup or a salad, veggies, fried rice and a choice of a protein for under $ 10 and be back out the door and headed back to the office or meeting. Glad to see these guys have taken this into account. Though, you should know that the $ 10 offering mostly comes in the protein department. Some may require more steak or chicken, which can be sparse. \\ n \\ nService is always quick and friendly. They do a wonderful job of memorizing orders. Rarely has it come to pass that my order has been mal - delivered. Quick on refills and I love that they always offer a to - go beverage. \\ \" Why, yes! I would love a diet coke to go! How thoughtful! \\ \" Pretty much always my thought process. \\ n \\ nThis place also does full dinner options and has sushi. Neither of which I have tried to date, but would happily oblige if the option was presented. \\ n \\ nThanks for the quick and entertaining lunch / service, Kabuto! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "true label: 2\n",
            "predicted label: 3\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1611287c8bcf4f578e0d4893f0bbcee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5cb08cc0d414bd5bebe681b82de13c9",
              "IPY_MODEL_9337e8d610844cf8bdf0377a284db4d9",
              "IPY_MODEL_4314d1e5d4514b77b3dda77174cc68b4"
            ],
            "layout": "IPY_MODEL_17db5db4af0c4f6488cd88ff5bd103c0"
          }
        },
        "d5cb08cc0d414bd5bebe681b82de13c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6f3b4045c1b411ab019218d2ff5c44b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_123b3d8e24e64627825be5bbf85246b4",
            "value": "Downloading builder script: "
          }
        },
        "9337e8d610844cf8bdf0377a284db4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeaa55a19a6e4024895bdbf1dec5608d",
            "max": 1652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1907319558642008eaec7d535cacb1d",
            "value": 1652
          }
        },
        "4314d1e5d4514b77b3dda77174cc68b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fce37305fb54fcf9355736cc3993212",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_31506f62dc7a4937a83abc4f5df8e31f",
            "value": " 4.21k/? [00:00&lt;00:00, 133kB/s]"
          }
        },
        "17db5db4af0c4f6488cd88ff5bd103c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f3b4045c1b411ab019218d2ff5c44b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "123b3d8e24e64627825be5bbf85246b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeaa55a19a6e4024895bdbf1dec5608d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1907319558642008eaec7d535cacb1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fce37305fb54fcf9355736cc3993212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31506f62dc7a4937a83abc4f5df8e31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39c15a4ad85541718068afe18c3d9aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbcb5ad7277a4e928359b5f177aeef3c",
              "IPY_MODEL_0563d1194dda460384d0fef128cc9578",
              "IPY_MODEL_e059e3ab58f34eca9803f94c84aa9a53"
            ],
            "layout": "IPY_MODEL_ee52f0aeb04d44698964ee02f072de36"
          }
        },
        "cbcb5ad7277a4e928359b5f177aeef3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65922efd98d24ae6a0ee9d669ec7bfdd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a4fe6592830b444f894b15681e501ef3",
            "value": "100%"
          }
        },
        "0563d1194dda460384d0fef128cc9578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0561fcbcb81d4c84837cb1f4a2127f9c",
            "max": 375,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce8a668445c440c4bf30427b74981665",
            "value": 375
          }
        },
        "e059e3ab58f34eca9803f94c84aa9a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_983e4cd11dd34adbb346858056e646de",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1cce1243aebe43e39cef37744d51a1a6",
            "value": " 375/375 [04:52&lt;00:00,  1.28it/s]"
          }
        },
        "ee52f0aeb04d44698964ee02f072de36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65922efd98d24ae6a0ee9d669ec7bfdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4fe6592830b444f894b15681e501ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0561fcbcb81d4c84837cb1f4a2127f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce8a668445c440c4bf30427b74981665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "983e4cd11dd34adbb346858056e646de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cce1243aebe43e39cef37744d51a1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}